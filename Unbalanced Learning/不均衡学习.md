# 不均衡学习

## 1. 何为不均衡学习？

通常二分类机器学习任务期望两种类别的样本是均衡的，即两类样本的总量接近相同。因为在梯度下降过程中，不同类别的样本量有较大差异时，很难收敛到最优解。但在很多真实场景下，数据集往往是不平衡的。也就是说，在数据集中，有一类含有的数据要远远多于其他类的数据。尤其是在风控场景下，负样本的占比要远远小于正样本的占比。

![img](D:\develop\github\MLStudy\Unbalanced Learning\img\imbalance.png)

考虑一个简单的例子，假设有10万个正样本（正常客户，标签为0）与1000个负样本（欺诈客户，标签为1），正负样本比例为100:1。如果直接送入模型中去学习，每一次梯度下降都使用全量样本，其中负样本所贡献的信息只有模型接收到的总信息的1/100，不能保证模型能很好地学习负样本。所以，需要一个分类器，既能有效地学习正样本的信息，同时又不会影响到负样本的学习。

下面总结几类解决样本不均衡问题的方法。



## 2.欠采样

### 2.1 何为欠采样

欠采样就是对训练集中多数类样本进行下采样，即去除一部分多数类中的样本使得正例、反例数目接近，然后再进行学习。

### 2.2 随机欠采样

随机欠采样顾名思义就是从多数类中随机选择一些样本从中移除。

缺点：

随机欠采样方法通过改变多数类样本比例以达到修改样本分布的目的，从而使样本分布较为均衡，但是这也存在一些问题。对于随机欠采样，由于采样的样本集合要少于原来的样本集合，因此会造成一些信息缺失，即将多数类样本删除有可能会导致分类器丢失有关多数类的重要信息。

为了克服随机欠采样方法导致的信息缺失问题，又要保证算法表现出较好的不均衡数据分类性能，出现了欠采样方法的代表性算法EasyEnsemble和BalanceCascade算法。

### 2.3 EasyEnsemble

（1）算法思想

基于**Bagging**的思想，每次从多数类中随机抽取和少数类相近的样本量，训练多个模型进行平均，这样基本不会损失多数类样本的信息。

（2）算法步骤

1）从多数类中有放回的随机采样n次，每次选取与少数类数目相近的样本个数，那么可以得到n个样本集合记作${S_{1maj},S_{2maj},...,S_{amaj}}$。
2）然后，将每一个多数类样本的子集与少数类样本合并并训练出一个模型，可以得到n个模型。
3）最终将这些模型组合形成一个集成学习系统，最终的模型结果是这n个模型的平均值。

![image-20210326104139804](D:\develop\github\MLStudy\Unbalanced Learning\img\EasyEnsemble.png)

### 2.4 BalanceCascade

（1）算法思想

基于**Boosting**的思想，从多数类中随机抽取和少数类相近的样本量，在全量样本上做预测，多数类中预测正确的样本下一轮迭代不再被选取，直到到达预设的迭代次数，这样可以保证每一轮迭代更多关注多数类中被分错的样本。

（2）算法步骤

BalanceCascade算法基于Adaboost，将Adaboost作为基分类器，其核心思路是：
1）在每一轮训练时都使用多数类与少数类数量相等的训练集，训练出一个Adaboost基分类器。
2）然后使用该分类器对全体多数类进行预测，通过控制分类阔值来控制假正例率（False Positive Rate），将所有判断正确的类删除。
3）最后，进入下一轮迭代中，继续降低多数类数量。

![image-20210326105840444](D:\develop\github\MLStudy\Unbalanced Learning\img\BalanceCascade.png)

> 参考文献：
>
> Liu X Y, Wu J, Zhou Z H. Exploratory undersampling for class-imbalance learning[J].IEEE Transactions on Systems, Man, and Cybernetics, Part B(Cybernetics),2009,39(2):539-550.



## 3.过采样

### 3.1 何为过采样

对训练集里的少数类进行“过采样”（oversampling），即增加一些少数类样本使得正、反例数目接近，然后再进行学习。

### 3.2 随机过采样

随机过采样就是在少数类中随机选择一些样本，然后复制所选择的样本添加到少数类中，相当于增加了少数类的样本量，保证正负样本均衡。

**缺点：**

对于随机过采样，由于需要对少数类样本进行复制来扩大数据集，造成模型训练复杂度加大。另一方面也容易造成模型的过拟合问题，因为随机过采样是简单的对初始样本进行复制采样，这就使得学习器学得的规则过于具体化，不利于学习器的泛化性能，造成过拟合问题。
为了解决随机过采样中造成模型过拟合问题，又能保证实现数据集均衡的目的，出现了过采样法代表性的算法SMOTE和Borderline-SMOTE算法。

### 3.3 SMOTE

**（1）算法思想**

SMOTE全称是Synthetic Minority Oversampling，即合成少数类过采样技术。SMOTE算法是对随机过采样方法的一个改进算法，由于随机过采样方法是直接对少数类进行重采用，会使训练集中有很多重复的样本，容易造成产生的模型过拟合问题。而SOMT算法的基本思想是对每个少数类样本$x_i$，从它的最近邻中随机选择一个样本$\hat{x}_i$（$\hat{x}_i$是少数类中的一个样本），然后在$x_i$和$\hat{x}_i$之间的连线上随机选择一个点作为新合成的少数类样本。

**（2）算法步骤**

SMOTE算法合成新少数类样本的算法描述如下：
1）对于少数类中的每一个样本$x_i$，以欧氏距离为标准计算它到少数类样本集$S_{min}$中所有样本的距离，得到其k近邻。
2）根据样本不平衡比例设置一个采样比例以确定采样倍率N，对于每一个少数类样本$x_i$，从其k近邻中随机选择若干个样本，假设选择的是$\hat{x}_i$。
3）对于每一个随机选出来的近邻$\hat{x}_i$，分别与$x_i$按照如下公式构建新的样本：
$$x_{new}=x_{i}+rand(0，1)×(\hat{x}_i-x)$$

下面用图文的方式描述SMOTE算法：

1）先随机选定一个少数类样本$x_i$。

![image-20210326114239565](D:\develop\github\MLStudy\Unbalanced Learning\img\smote1.png)

2）找出这个少数类样本i的K个近邻（假设K=5），5个近邻已经被圈出。

![image-20210326114307865](D:\develop\github\MLStudy\Unbalanced Learning\img\smote2.png)

3）随机从这K个近邻中选出一个样本（用绿色圈出来了）。

![image-20210326114330022](D:\develop\github\MLStudy\Unbalanced Learning\img\smote3.png)

4）在少数类样本：和被选中的这个近邻样本之间的连线上，随机找一点。这个点就是人工合成的新的样本点（绿色正号标出）。

![image-20210326114355820](D:\develop\github\MLStudy\Unbalanced Learning\img\smote4.png)

SMOTE算法摒弃了随机过采样复制样本的做法，可以防止随机过采样中容易过拟合的问题，实践证明此方法可以提高分类器的性能。但是SMOTE算法也存以下两个缺点：

1）由于对每个少数类样本都生成新样本，因此容易发生生成样本重叠的问题。
2）在SMOTE算法中，出现了过度泛化的问题，主要归结于产生合成样本的方法。特别是，SMOTE算法对于每个原少数类样本产生相同数量的合成数据样本，而没有考虑其邻近样本的分布特点，这就使得类间发生重复的可能性增大。

解释缺点2）的原因：结合前面所述的SMOTE算法的原理，SMOTE算法产生新的人工少数类样本过程中，只是简单的在同类近邻之间插值，并没有考虑少数类样本周围多数类样本的分布情况。如下图所示，绿色正号1、2分布在多数类样本周围，它们离多数类样本最近，这就导致它们有可能被划分成多数类样本。因此从下图可以看出，SMOTE算法的样本生成机制存在一定的盲目性。

![image-20210326115324625](D:\develop\github\MLStudy\Unbalanced Learning\img\smote5.png)

为了克服以上两点的限制，多种不同的自适应抽样方法相继被提出，其中具有代表性的算法包括Borderline-SMOTE算法。

### 3.4 Borderline-SMOTE

对于Borderline-SMOTE算法，最重要的就是用于识别少数类种子样本的方法。在Borderline-SMOTE算法中，识别少数类种子样本的过程如下：

1）首先，对于每个少数类样本$x_i\in{S_{min}}$，确定一系列最近邻样本集，称该数据集为$S_{i-KNN}$，且$S_{i-KNN}\in{S}$。
2）然后，对每个样本$x_i$，判断出最近邻样本集中属于多数类样本的个数，即：$|S_{i-KNN}\cap{S_{maj}}|$。
3）最后，选择满足下面不等式的$x_i$：

$${k\over2}<|S_{i-KNN}\cap{S_{maj}}|<k$$

上面式子表明，只有最近邻样本集中多数类多于少数类的那些$x_i$才会被选中形成“危险集”（DANGER）。因此，DANGER集中的样本代表少数类样本的边界（最容易被错分的样本）。然后对DANGER集中使用SMOTE算法在边界附近产生人工合成少数类样本。

我们可以看出，如果$|S_{i-KNN}\cap{S_{maj}}|=k$。即：$x_i$的所有k个最近邻样本都属于多类。如下图所示的样本点C，我们就认为样本点C是噪声且它不能生成合成样本。

![image-20210327191910290](D:\develop\github\MLStudy\Unbalanced Learning\img\smote6.png)

通过上面的介绍，我们对Borderline-SMOTE算法有了一定了解。下面通过流程图看一下详细过程：

![image-20210327200656887](D:\develop\github\MLStudy\Unbalanced Learning\img\smote7.png)

流程图中，训练样本集为F，少数类样本$S_{min}={f_i，f_2,…,f_n}$。

1）步骤一：

（i）计算少数类样本集$S_{min}$中每一个样本在训练集F中的k个最近邻。
（ii）然后，根据这k个最近邻对$S_{min}$中的样本进行归类：

- 假设这k个最近邻都是多数类样本，则我们将该样本定义为噪声样本，将它放在$N^{'}$集合中。
- 若这k个最近邻都是少数类样本，则该样本是远离分类边界的，将其放入S集合中。
- 最后，若k个最近邻即有多数类样本又有少数类样本，则认为是边界样本，放入B集合中。

2）步骤二：

（i）设边界样本集$B={f^{'}_1，f^{'}_1,…,f^{'}_n}$，计算B集合中的每一个样本$f^{'}_i(i=1,2,…,n)$在少数类样本集$S_{min}$中的K个最近邻，组成集合$f_{ij}$。

（ii）随机选出$s(1<s<n)$个最近邻。

（iii）计算出它们各自与该样本之间的全部属性的差值$d_{ij}=f^{'}_{i}-f_{ij},j=1,2,…,s$。

（iv）然后乘以一个随机数$r_{ij},r_{ij}\in{(0,1)}$。如果$f_{ij}$是$N^{'}$集合或S集合中的样本，则$r_{ij}\in{(0,0.5)}$。

（v）最后生成的人工少数类样本为：$h_{ij}=f^{'}_{i}-r_{ij}*d_{ij},j=1,2,…,s$。

3）步骤三：

重复步骤2的过程，直到生成人工少数类样本的数目满足要求，达到均衡样本集的目的后结束算法。

> 参考文献：
>
> Han H, Wang W Y, Mao B H. Borderline-SMOTE: a new over-sampling method in imbalanced data sets learning[C]. International Conference on Intelligent Computing. Springer, Berlin, Heidelberg,2005:878-887.

### 3.5 LGB + SMOTE

**（1）算法思想**

由于SMOTE算法是基于样本空间进行插值的，会放大数据集中的噪声和异常，因此要对训练样本进行清洗。我们可以使用LightGBM算法对数据进行拟合，将预测结果较差的样本权重降低，并且不参与SMOTE算法的插值过程。

**（2）处理过程**

1）首先，使用LightGBM模型对样本进行清洗，针对头部和尾部预测不准的样本，不参与SMOTE过采样，这里生成分类可信度较高的样本集；

2）然后，使用SMOTE算法对清洗后的样本集进行过采样；

3）最终，将采样后的新样本与旧样本合并返回，训练新模型。



## 4.代价敏感学习

### 4.1 代价矩阵

采样算法从数据层面解决不平衡数据的学习问题；在算法层面上解决不平衡数据学习的方法主要是基于代价敏感学习算法（Cost-Sensitive Learning）。在现实任务中常会遇到这样的情况：不同类型的错误所造成的后果不同。例如在医疗诊断中，错误地把患者诊断为健康人与错误地把健康人诊断为患者，看起来都是犯了“一次错误"，但是后者的影响是增加了进一步检查的麻烦，前者的后果却可能是丧失了拯救生命的最佳时机；再如，门禁系统错误地把可通行人员拦在门外，将使得用户体验不佳，但错误地把陌生人放进门内，则会造成严重的安全事故；在信用卡盗用检查中，将正常使用误认为是盗用，可能会使用户体验不佳，但是将盗用误认为是正常使用，会使用户承受巨大的损失。为了权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价"（unequal cost）。

代价敏感学习方法的核心要素是代价矩阵，如表1所示。其中$cost_{ij}$表示将第i类样本预测为第类样本的代价。一般来说，$cost_{ij}=0$；若将第0类判别为第1类所造成的损失更大，则$cost_{01}>cost_{10}$；损失程度相差越大，$cost_{01}$与$cost_{10}$的值差别越大。当$cost_{01}$与$cost_{10}$相等时为代价不敏感的学习问题。

![image-20210327202310820](D:\develop\github\MLStudy\Unbalanced Learning\img\cost01.png)

### 4.2 代价敏感学习方法

基于以上代价敏感矩阵的分析，代价敏感学习方法主要有以下三种实现方式，分别是：

1）从学习模型出发，对某一具体学习方法的改造，使之能适应不平衡数据下的学习，研究者们针对不同的学习模型如感知机、支持向量机、决策树、神经网络等分别提出了其代价敏感的版本。以代价敏感的决策树为例，可以从三个方面对其进行改造以适应不平衡数据的学习，这三个方面分别是决策阈值的选择方面、分裂标准的选择方面、剪枝方面，这三个方面都可以将代价矩阵引入。

2）从贝叶斯风险理论出发，把代价敏感学习看成是分类结果的一种后处理，按照传统方法学习到一个模型，以实现损失最小为目标对结果进行调整，优化公式如下所示。此方法的优点在于它可以不依赖所用的具体分类器，但是缺点也很明显，它要求分类器输出值为概率。

$$H(x)=argmin(\displaystyle\sum_{j\in{\{-,+\}}}p(j|x)C(i,j))$$

3）从预处理的角度出发，将代价用于权重调整，使得分类器满足代价敏感的特性，下面讲解一种基于Adaboost的权重更新策略AdaCost算法。

### 4.3 代价敏感加权方案

通过对少数类样本进行加权处理，使得模型进行均衡训练。代价敏感加权在传统风控领域又叫作展开法，依赖于已知表现样本的权重变化。它假设拒绝样本的表现可以通过接收样本直接推算得到。虽然代价敏感加权增大了负样本在模型中的贡献，但没有为模型引入新的信息，既没有解决选择偏误的问题，也没有带来负面影响。

逻辑回归可以通过参数class_weight=“balanced”调整正负样本的权重，使得正负样本总权重相同。类权重计算方法如下：

$$weight={n\_samples\over{n\_classes×np.bincount(y)}}$$

其中，n_samples为样本数，n_classes为类别数量，np.bincount(y)会输出每个类的样本数，例如y=[1,0,0,1,1]，则np.bincount(y)=[2,3]。

大多数情况下样本加权可以增强模型的表现。

### 4.4 AdaCost算法

要想了解AdaCost算法，我们得先知道Adaboost算法，如下图所示。Adaboost算法通过反复迭代，每一轮迭代学习到一个分类器，并根据当前分类器的表现更新样本的权重，如图中红框所示，其更新策略为正确分类样本权重降低，错误分类样本权重增大，最终的模型是多次迭代模型的一个加权线性组合。分类越准确的分类器将会获得越大的权重。

![image-20210328164241288](D:\develop\github\MLStudy\Unbalanced Learning\img\adaboost.png)

AdaCost算法修改了Adaboost算法的权重更新策略，其基本思想是对代价高的误分类样本大大地提高其权重，而对于代价高的正确分类样本适当地降低其权重，使其权重降低相对较小。总体思想是代价高的样本权重增加得多降低的少。其样本权重按照如下公式进行更新。其中$\beta_{+}$和$\beta_{-}$分别表示样本被正确和错误分类情况下的β的取值。

![image-20210328164117792](D:\develop\github\MLStudy\Unbalanced Learning\img\adacost.png)

其中：

$$\beta_{+}=-0.5C_i + 0.5$$

$$\beta_{-}=0.5C_i + 0.5$$

参考文档：

1.AdaCost: Misclassication Cost-sensitive Boosting

2.代码实现：https://github.com/joelprince25/adacost

3.代价敏感分类模型：http://albahnsen.github.io/CostSensitiveClassification/

## 5.半监督学习

### 5.1 何为半监督学习

#### 5.1.1 何为半监督学习

SMOTE算法所产生的新样本仍是基于样本产生的，没有为模型引入拒绝样本信息。这里介绍如何通过半监督学习（Semi-Supervised Learning）对拒绝样本进行预测。从而使模型获得更多的信息。所谓半监督学习，即让学习器不依赖于外界交互，自动利用无标签样本来提升学习性能。

传统的半监督学习可分为两类：纯半监督学习和直推式学习。

- **纯半监督学习**认为，当前看到的无标签样本只是样本空间中的一小部分。未来还会有更多的无标签样本出现。其假定训练数据中的无标签样本并非待预测的数据。
- **直推式学习**只尝试对学习过程中的无标签样本进行预测，学习的目的就是在这些无标签样本上获取最优泛化性能。

两种半监督学习的使用逻辑如下图：

![图片1](D:\develop\github\MLStudy\Unbalanced Learning\img\半监督学习.png)

#### 5.1.2 前提假设

半监督学习有三点假设：

- 平滑假设：特征相似的样本具有相同的标签。
- 聚类假设：同一聚类下的样本有相同的标签。
- 流形假设：同一流形结构下的样本有相同的标签。

### 5.2 PU-learning

正例和无标记样本学习（Learning from Positive and Unlabled Example）简称PU-learning，是一种半监督的二元分类模型，通过标注过的正样本和大量未标注的样本训练出一个二元分类器。

与普通分类问题不同，PU问题中P的规模通常相当小，扩大正样本集合也比较困难；而U的规模通常很大，比如在网页分类中，未标识的网页资源可以非常廉价、方便的从网络中获取。引入U的目的就是降低人工分类的预备工作量，同时提高精度，尽可能达到自动分类的效果。

PU-learning方法在许多领域内都有应用，比如：

- 检索：从大量无标注的样本中选取特定的样本，比如人脸标注。
- 异常检测：异常点检测，恶意url检测，致病基因检测等。
- 序列数据检测：负样本的分布随着时间改变，这样传统的分类将不再适合，PU 只需要更新未标注样本，这样的花销更小，比如垃圾邮件检测，由于存在对抗，负样本（垃圾邮件）的形式一直在变，而非垃圾则一般相对稳定状态。

#### 5.2.1 实现方法

目前 PU-learning方法可分为两类：

  直接法：利用正样本集和未标记样本集直接训练分类器，对最后得到的概率进行校正。在满足一定条件假设下，通过数学公式推导可以证明，由正样本+未标记样本训练出的分类器和正样本+负样本训练出的分类器存在一个常数概率转换关系。

  两步法：从未标注数据中识别出有效的负样本，然后利用正负样本迭代训练分类器。

这里我们重点介绍两步法的使用，两步法的两个步骤如下图所示，具体概括为：

  第1步：根据已标注过的正样本P在未标注样本集U中找出可靠的负样本集合(Reliable Negative Examples，简称RN)，将PU问题转化为二分类的问题；

  第2步：利用正负样本通过迭代训练得到一个二元分类器。

理论上已经证明：如果最大化未标注样本集U中负样本的个数，同时保证正样本被正确分类，则会得到一个性能不错的分类器。

![PU-learning的两步法](D:\develop\github\MLStudy\Unbalanced Learning\img\PU-learning的两步法.png)

上述两个步骤中，找出RN以及训练二元分类器都有很多方法可以选择，下面对这些方法进行简单的介绍。

#### 5.2.2 计算 RN

##### 5.2.2.1 朴素贝叶斯分类器

使用朴素贝叶斯（Naive Bayesian，NB）分类方法计算 RN，可以简单参考以下步骤：

  把 P 中的每个样本标记为类别 1；

  把 U 中的每个样本标记为类别-1；

  使用 P 和 U 训练得到贝叶斯分类器；

  对 U 中的每个样本使用上述分类器进行分类，如果分类结果为-1，则把该样本加入 RN。

##### 5.2.2.2 Rocchio 技术

Rocchio 是一种早期的文档分类技术，其基本思想是：每个样本可以用一组特征向量来表示，特征值可以使用TF-IDF方式计算得到。

设全部样本集合为D，类别为$c_j$的训练样本集合为$C_j$。通过对每个类别$c_j$构造一个原型向量$\vec{c}_j$，可以得到 Rocchio 分类器：

 ![image-20210328184548513](D:\develop\github\MLStudy\Unbalanced Learning\img\rocchio.png)

 其中，α和β分别调节与类别$c_j$相关及不相关类别的权重。

对一个待分类的样本t，使用余弦相似度计算其与每个类别的原型向量的相似距离，取距离最小的类别作为该样本的类别。

使用Rocchio算法与上述NB分类器计算RN的步骤很类似，只要把上述算法中第3步的分类器替换为 Rocchio 分类器即可。

##### 5.2.2.3 Spy算法

Spy的基本思想是从P中划分出一个子集S，将S中的样本放到U中，从而得到新的正样本集P-S和未标识样本集U+S。使用P-S作为正样本，U+S作为负样本，利用迭代的EM算法进行分类，当分类结束后，利用对那些**「间谍」**样本的标识，确定一个参数阈值th，再对U中的文档进行划分得到可靠的反样本集合RN。其中，从P中划分子集S的数量比例一般为15%。算法步骤描述如下：

  RN集合置空；

  从P中随机选取子集S，得到新的正样本集PS=P-S和未标识样本集US=U+S，记 PS 中各个样本类别为1，US各个样本类别为-1；

  PS和US作为训练集，用I-EM算法训练得到一个贝叶斯分类器；

  使用子集S确定出一个概率阈值th；

  对US中的每个样本d使用贝叶斯分类器计算其属于正类别的概率P(1|d)，如果小于阈值概率th，则把其加入RN集合。

##### 5.2.2.4 1-DNF算法

1-DNF算法的基本思想是：对于每个特征，如果其在P集合中的出现频次大于N集合，记该特征为正特征 (Positive Feature, PF)，所有满足该条件的特征组成一个PF集合。对U中的每个样本，如果其完全不包含PF集合中的任意一个特征，则该样本应加入RN。算法步骤描述如下图所示：

![image-20210328185142534](D:\develop\github\MLStudy\Unbalanced Learning\img\1-DNF技术.png)

#### 5.2.3 训练分类器

##### 5.2.3.1 SVM

使用 SVM 直接对 P 和 RN 进行训练得到分类器。

##### 5.2.3.2 S-EM

EM 算法主要由 Expectation 和 Maximization 两个步骤组成。前者对缺失标签的数据打上标签；后者则用全部数据一起计算模型参数。算法步骤描述如下：

  对 P 中的每个样本标记为类别 1；

  对 RN 中的每个样本标记为类别-1；

  Q=U-RN 中的样本起初没有任何类别标签，在 EM 算法第一次迭代完成时，这些数据将会具有一个基于概率的类别标签。在后续的迭代中，都使用上一轮更新完类别标签的数据集 Q，直至 EM 算法收敛。

在上述流程中，每次迭代使用 Naive Bayesian 算法修正Q集合中的数据标签。

##### 5.2.3.3 PEBL 算法

PEBL算法主要思想是使用SVM迭代地从U-RN中抽取出更多的负样本，并把它们放到RN集合中，直至U-RN中没有可以被分为负样本的数据为止。算法步骤如下：

- 对 P 中的每个样本标记为类别 1；

- 对 RN 中的每个样本标记为类别-1；

- 令 i=1，Q=U-RN，开始以下的循环：

  使用 P 和 RN 训练一个 SVM 分类器 Si；

  使用 Si 对 Q 中的样本进行分类，把其中所以分类为-1的样本记为W；

  如果W为空，则结束循环；否则：Q = Q-W,  RN = RN ∪ W,  i = i + 1。

##### 5.2.3.4 Roc-SVM 算法

PEBL 算法中得到的最后一个分类器不一定是最优分类器，为此，对该算法进行一些改进，得到了Roc-SVM算法。算法步骤如下：

- 使用 PEBL 算法直至收敛，记最后一个分类器为S_last；
- 使用S_last对P进行分类；
- 如果P中超过8%的样本被分为负样本，则选择S1作为最终的分类器；否则，选择S_last作为最终分类器。

由于 SVM 算法对噪声很敏感，如果在迭代过程中，把Q中的一些正样本错分为-1而划分到RN中，那么会导致最终的分类器 S_last 性能很差，这也是 PEBL算法的一个缺陷。为此，需要对S_last的分类性能进行评估，看是否选择其作为最终分类器。选择8%作为判断阈值也是一个保守的做法，以防选择一个性能不好的分类器。

上述的选择S1或S_last 的做法其实还是欠妥，因为这两个分类器可能性能都很差。S1性能差是因为初始的RN集合中可能包含很少的负样本，不能体现出负样本的整体分布情况；S_last性能差则是由于PEBL算法在某个迭代过程中把一些正样本错分到RN中。为此，我们可以选择使用Spy或Rocchio算法得到初始的RN，这样可以使S1更加稳健。有一点要注意的是：多数情况下，最佳分类器可能并不是 S1 或 S_last，而是在迭代过程中产生的某一个分类器，然而，这个最佳分类器却是很难被获取的。

#### 5.2.4 总结

我们可以发现，其实基本上这类PU-learning的解决方案都是偏工程手法，具体在分类模型的选择上并没有特殊的要求，可以自行选择和调试，但是鉴于大多会遇到重复迭代的问题，所以尽量选择高效的分类模型来做中间分类器的训练，比如XGBoost、LR等。

### 5.3 S3VM

**（1）算法思想**

S3VM（Semi-supervised Support Vector Machine，半监督支持向量机）的基本思想是，在不考虑无标签样本的情况下尝试寻找最大间隔划分超平面，加入无标签样本后，期望调整该超平面，使其尽可能穿过数据低密度区域。如下图所示，加号代表有标签正样本，减号代表有标签负样本，圆圈代表无标签样本。

**（2）TSVM算法原理**

S3VM中最典型的算法是TSVM（Trasacive Ssumport vectorMacthine）算法。TSVM算法尝试给无标签样本随机打标签，遍历每个样本的每一种标签的组合，然后为每一组标签分别寻找一个在总体上最大化的超平面，寻得最优超平面后每个样本被标记为哪一类，其预测结果就属于哪一类。如下是TSVM算法的目标函数：

![image-20210328204619550](D:\develop\github\MLStudy\Unbalanced Learning\img\tsvm.png)

其中，(w,b)是超平面的两个参数，$\xi_i(i=1,2,…,l)$是有标签样本的松弛变量，$\xi_i(i=l+1,l+2,…,m)$是无标签样本的松弛变量。$C_l$和$C_u$是权重，如果更看重对有标签样本的区分度，应该将$C_l$设置为大于$C_u$；如果希望重点关注无标签样本，则应当使$C_u$更大一些。

但是遍历所有组合显然是一种低效的求解方式，TSVM中采用局部搜索来寻找最优超平面。首先用有标签样本训练一个支持向量机，然后对无标签样本进行预测得到伪标签。接下来，分别计算每个样本到分类平面的距离：

$$H_i=\boldsymbol{wx_i}b$$

接下来就可以计算出松弛变量的大小了。对于任意一组标签相反的原无标签样本，如果两个松弛变量之和大于2，则交换两者的标签，然后重新估计最优超平面。通过不断迭代，最终可以收敛到一个对业务有明显帮助的结果。

算法过程如图所示：

![image-20210328205812644](D:\develop\github\MLStudy\Unbalanced Learning\img\tsvm2.png)

由于TSVM算法的时间复杂度依赖于样本量，实际使用中需要再多加权衡。变量不宜过多，通常（至多）选择线性模型中权重最大的前10个变量作为特征，进行半监督训练。与监督学习不同，随着变量的增多，半监督模型效果通常不会有显著变化，反而会为决策过程引入更多的噪声，引起模型的稳定性问题。

### 5.4 LP

标签传播算法（Label Propagation，LP）是一种基于图的半监督学习方式，常用于信用模型中的负样本衍生，在欺诈检测中经常作为一种社区发现算法用于识别团伙欺诈。

**（1）算法原理与流程**

LP的核心思想非常简单，就是半监督学习三大假设之一的平滑假设，即相似的样本具有相同的标签。LP算法包括两个步骤：

1）构造相似矩阵；

2）通过相似度进行传播。

参考资料：

https://www.youtube.com/watch?v=HDzBPkwHWuY

## 6.不均衡学习的评价方法

### 6.1 评价指标敏感度

我们用评价指标敏感度来衡量评价指标受数据不均衡影响的大小程度，受影响大为敏感，反之不敏感。针对数据不均衡问题，我们应尽量选用不敏感的评价指标。

常用评价指标对于样本不均衡问题的敏感度，如下图所示：

![img](D:\develop\github\MLStudy\Unbalanced Learning\img\评价指标敏感度.jpg)

如上图，敏感度低的评价指标主要有AUC、G-Mean、WA等；敏感度高的评价指标主要有ACC、F-Meature、MI等。

因此，对于不均衡数据，我们通常都会选择AUC作为评价指标。

### 6.2 G-Mean

G-Mean可用于评价不均衡数据的模型表现，其计算公式如下：

$$
G-Mean=\sqrt{TPR·TNR}=\sqrt{{TP\over{TP+FN}}×{TN\over{TN+FP}}}
$$

### 6.3 AUC

参考AUC指标的说明

### 6.4 进一步思考

**问题真的解决了吗？**

经过前半部分的分析介绍，看起来我们已经可以根据自己的数据来选择适合自己的评价指标，完成反欺诈模型的指标评价。但我们不妨停下来想一想，问题真的迎刃而解了吗？

在此我们认为至少还存在三个问题，需要进一步思考。

1.基于样本区分能力的评价指标是否合理

2.测试数据如何选取

3.如何将理论化、难以理解的评价指标，转化为业务部门易于理解的业务指标

接下来我们一起来观察在不均衡条件下，相对不敏感的评价指标AUC得分所受的影响。AUC（Area under the Curve of ROC）由ROC曲线计算而来，其值为ROC曲线下方面积，常用来判断二分类预测模型在数据上表现的优劣。AUC值越高，我们认为模型对于样本区分能力越强，对于正负样本区分能力越好。

举一简单样例进行说明，假设原始测试数据由50个负样本与5个正样本组成的。针对于原始测试数据，我们只调整测试数据中一个正样本数据特征，得到测试数据集A与B，使用相同模型获得三个数据集的样本得分。

样本得分越高，标志着样本被模型判断为正样本的置信度越高。在三个数据集样本得分上，负样本得分完全相同，正样本得分在被调整的正样本上有微小波动。

在下图中，被标红的正样本得分标志着A、B数据集中调整的正样本的得分，以此我们来观察在样本不均衡情况下，正样本极小波动对于AUC得分所造成的影响。

![img](D:\develop\github\MLStudy\Unbalanced Learning\img\auc1.png)

原始数据集：正样本得分 0.9,0.9,0.4,0.1,0.1  AUC得分0.5

![img](D:\develop\github\MLStudy\Unbalanced Learning\img\auc3.png)

数据集A：正样本得分0.9,0.9,0.4, **0.3** ,0.1 AUC得分0.54

![img](D:\develop\github\MLStudy\Unbalanced Learning\img\auc2.png)

数据集B：正样本得分0.9, **0.7**,0.4, 0.1,0.1 AUC得分0.46

结合上图，我们可观察到，当少数类样本中有一样本得分由0.1升为0.3时，对应的全局AUC提升了10%，在模型评测中已可算为重大的模型提升。但在实际分类应用时，单个样本得分提升至0.3，对于最后的分类结果可以说影响微乎其微。

同样，当单个少数类样本得分由0.9变为0.7时，模型AUC评分下降了10%。但在实际分类应用时，其影响也并无AUC指标表示的差别如此之大。

**（1）合理选择评价指标**

总结从前面AUC示例学习到的经验，我们认为在应用此类评价指标时，应注意两点：第一，如非必要尽量不使用全局数据进行评价，而应锚定指定阈值或一定数量样本，使用局部AUC指标计算；第二，可引入专家系统，人工赋予正样本危害度权重大小，以此为基础完成评价，可参考使用经典的MAP、NDCG等推荐排序指标。

在此简单介绍MAP指标。MAP（Mean Average Precision平均准确率）来源于自然语言处理，其计算方式为使用正样本在测试数据中的排序序号除以对应正样本在模型结果中的排序序号后求和。MAP值越高，意味着模型的检索能力越强，也即模型对于正负样本区分性越强。

例如：假设有一份测试数据，其中1~7为正样本，其序号越大代表案件危害性越大。在此使用MAP评价两个模型。模型1检索识别出4个正样本，其序号分别为1, 2, 4, 7；模型2检索出3个正样本，其序号分别为1,3,5。则模型1的MAP为(1/1+2/2+3/4+4/7)/4=0.83。模型2的MAP为(1/1+2/3+3/5+0+0)/5=0.45。

**（2）合理选择评测数据**

关于评测数据的选择，在数据分布均衡的模型评测中，训练集、测试集由全部数据按一定比例切分而来，无需担心由不均衡数据导致的各种问题。

但在不均衡数据上，由于正样本极度稀少，如按传统切分方式，那么可能造成两种情况：测试集中正样本数据极少，不足以客观评价算法；训练集中正样本数据极少，无法充分训练数据。

为解决上面的问题，有时会采取变通的方式，使用固定数目正样本加指定数据随机采样负样本的样本混合策略来完成测试数据的提取，进行模型评测。显然在此情况下，评测指标（如P/R值等）很大程度上受测试数据正负样本比影响。

故针对欺诈交易识别问题，结合实际应用经验，我们推荐较合理的测试数据为：在有一定案发量前提下的一段时间内全部交易数据。采用此种数据进行测试，可回溯测试模型在真实线上数据的效果表现。在条件有限的情况下，亦可采用有案件的各天交易数据进行评测，但此时欺诈交易模式突变或当天案发量极少（小于5笔）时，存在评测指标波动的风险。

**（3）评价指标应结合实际业务**

通过上述分析，我们终于选取了适宜的反欺诈评测指标，但此时一个更棘手的问题又摆在我们面前：业务部门作为反欺诈模型的应用方往往难以理解我们复杂的评价指标，并对于模型效果难以通过指标直观发现其价值，往往无法顺畅地沟通。

当我们用一个较好的指标评价模型时，给业务部门直接反馈技术评价指标，我相信对于绝大部分金融机构业务人员而言，是很难直观的将其与实际业务中所面对的交易相关数据进行结合。

因此，技术人员需要用尽可能贴合业务的方式更好的描述指标，展现模型效果。通常在反欺诈模型应用中，我们常用覆盖住一定比例案件的情况下，模型的误报率（即每判别一个正样本，牺牲负样本的比例）来与业务部门沟通。基于此，业务部门可直观得到在设定案件覆盖率的情况下，每日需处理的模型误报量及对应模型所能识别的案件量。

## 7.如何选择算法

- 在正负样本都非常少的情况下，应该采用数据合成的方式，例如：SMOTE算法和Borderline-SMOTE算法。
- 在正负样本都足够多且比例不是特别悬殊的情况下，应该考虑采样、加权或半监督的方法。

## 8. 不平衡学习的概率校准

对于不平衡学习，为了保证训练数据的均衡，我们采用了上采样、下采样或者其他处理方法，这使得实际样本的分布与建模样本的分布存在差异，虽然不影响模型的排序性能（为什么？），但是预测概率无法反映业务中的实际概率，如果模型应用时对预测概率的实际意义有要求，这就需要我们对预测概率进行校准。

此外，不同数据或者不同算法训练出来的模型，其预测概率不具有可比性，如果想要对结果进行融合，可以选择下面的方法：

- 采用LR构建二级模型；
- 子模型概率校准后再叠加；

> 详细内容可参考score calibration中的相关描述。







